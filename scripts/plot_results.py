#!/usr/bin/env python3
"""
Plot benchmark results from a summary CSV generated by orchestrators.

Inputs:
  --summary: path to summary.csv (required)
  --out-dir: directory to write plots (required)

The CSV can be either full or latency-only.
Full columns:
    transport,payload,rate,run_id,sub_tps,p50_ms,p95_ms,p99_ms,pub_tps,sent,recv,errors,artifacts_dir,max_cpu_perc,max_mem_perc,max_mem_used_bytes
Latency-only columns:
    transport,payload,rate,run_id,p50_ms,p95_ms,p99_ms

Outputs:
    - throughput_vs_rate_payload<bytes>.png
    - p99_vs_rate_payload<bytes>.png
    - throughput-vs-fanout_payload<bytes>_rate<r>.png (if fanout rows exist)
    - max-cpu-vs-fanout_payload<bytes>_rate<r>.png (if fanout rows exist)
    - max-memory-vs-fanout_payload<bytes>_rate<r>.png (if fanout rows exist)
    - gallery.md (Markdown file embedding all figures)
"""
import argparse
import csv
import os
import math
import re
import sys
from collections import defaultdict
from typing import Tuple


def parse_args() -> argparse.Namespace:
    p = argparse.ArgumentParser()
    p.add_argument("--summary", required=True, help="Path to summary.csv")
    p.add_argument("--out-dir", help="Output directory for plots (default: 'plots' subdirectory in summary's folder)")
    p.add_argument("--only-latency-vs-payload", action="store_true", help="Only generate Latency vs Payload plots")
    return p.parse_args()


# Marker and linestyle mapping per transport/broker for consistent visuals
# Supports labels like 'mqtt_emqx' and 'mqtt-emqx' (fanout plots)
MARKER_MAP = {
    "mqtt_mosquitto": "o",
    "mqtt_emqx": "s",
    "mqtt_hivemq": "^",
    "mqtt_rabbitmq": "D",
    "mqtt_artemis": "v",
    "mqtt": "o",
    "redis": "x",
    "nats": "P",
    "zenoh": "h",
    "zenoh_mqtt": "+",
    "rabbitmq": "*",
}

LINESTYLE_MAP = {
    "mqtt_mosquitto": "-",
    "mqtt_emqx": "--",
    "mqtt_hivemq": "-.",
    "mqtt_rabbitmq": ":",
    "mqtt_artemis": "-",
    "mqtt": "-",
    "redis": "--",
    "nats": "-.",
    "zenoh": "-",
    "rabbitmq": ":",
}

_MARKERS_CYCLE = ["o", "s", "^", "D", "v", "P", "X", "*", "h", "+", "x"]
_STYLES_CYCLE = ["-", "--", "-.", ":"]


def _norm_label(lbl: str) -> str:
    return (lbl or "").strip().lower().replace("-", "_")


def style_for(lbl: str) -> Tuple[str, str]:
    key = _norm_label(lbl)
    marker = MARKER_MAP.get(key)
    # All lines solid by default; keep marker distinct per broker/transport
    linestyle = "-"
    if marker is None:
        # Deterministic fallback based on label hash
        idx = abs(hash(key))
        marker = _MARKERS_CYCLE[idx % len(_MARKERS_CYCLE)]
    return marker, linestyle


def load_records(csv_path: str):
    recs = []
    with open(csv_path, newline="") as f:
        rd = csv.DictReader(f)
        for r in rd:
            try:
                item = {
                    "transport": r["transport"],
                    "payload": int(r["payload"]),
                    "rate": int(r["rate"]),
                    "sub_tps": float(r.get("sub_tps", "")) if r.get("sub_tps", "") else float("nan"),
                    "p50_ms": float(r.get("p50_ms", "")) if r.get("p50_ms", "") else float("nan"),
                    "p95_ms": float(r.get("p95_ms", "")) if r.get("p95_ms", "") else float("nan"),
                    "p99_ms": float(r["p99_ms"]) if r["p99_ms"] else float("nan"),
                    "max_cpu": float(r.get("max_cpu_perc", "") or float("nan")),
                    "max_mem_perc": float(r.get("max_mem_perc", "") or float("nan")),
                    "max_mem_bytes": float(r.get("max_mem_used_bytes", "") or float("nan")),
                    "avg_cpu": float(r.get("avg_cpu_perc", "") or float("nan")),
                    "avg_mem_perc": float(r.get("avg_mem_perc", "") or float("nan")),
                    "avg_mem_bytes": float(r.get("avg_mem_used_bytes", "") or float("nan")),
                    "connections": int(r.get("connections", "") or 0),
                    "active_connections": int(r.get("active_connections", "") or 0),
                    "run_id": r.get("run_id", ""),
                }
                # Extract pairs 'n<NNN>' from run_id if present
                rid = item.get("run_id", "")
                pairs = None
                if rid:
                    m = re.search(r"[_-]n(\d+)(?:[_-]|$)", rid)
                    if m:
                        try:
                            pairs = int(m.group(1))
                        except Exception:
                            pairs = None
                item["pairs"] = pairs
                recs.append(item)
            except Exception:
                # Skip malformed rows
                continue
    return recs


def unique_sorted(seq):
    return sorted(set(seq))


def dedupe_by_pairs(records_list: list) -> list:
    """Deduplicate records by pairs count, keeping the last entry for each pairs value.
    
    This handles cases where multiple benchmark runs with the same pairs count
    exist in the summary CSV (e.g., from multiple executions or appending).
    """
    by_pairs = {}
    for r in records_list:
        pairs = r.get("pairs")
        if pairs is not None:
            by_pairs[pairs] = r  # Later entries overwrite earlier ones
    return list(by_pairs.values())


def add_legend_top(ax, fig, max_cols: int = 4, reserve_top: float = 0.82) -> None:
    """Place a de-duplicated legend at the top of the figure and reserve
    vertical space to avoid overlap with the title.

    reserve_top: fraction of figure height allocated to axes (leave 1-reserve_top for legend).
    """
    handles, labels = ax.get_legend_handles_labels()
    # De-duplicate while preserving order
    seen = set()
    handles2, labels2 = [], []
    for h, lbl in zip(handles, labels):
        if lbl in seen:
            continue
        seen.add(lbl)
        handles2.append(h)
        labels2.append(lbl)
    if not handles2:
        # Still tighten layout even if no legend
        try:
            fig.tight_layout()
        except Exception:
            pass
        return
    ncol = min(len(labels2), max_cols)
    # Reserve space for top legend, then place it
    try:
        fig.tight_layout(rect=(0, 0, 1, reserve_top))
    except Exception:
        pass
    fig.legend(handles2, labels2, loc="upper center", bbox_to_anchor=(0.5, 0.99), ncol=ncol, frameon=False)


def format_pairs_axis(ax, data_xs: list) -> None:
    """Format the x-axis for pairs plots with scientific notation like 2×10³."""
    from matplotlib.ticker import FuncFormatter, FixedLocator
    
    def sci_formatter(x, pos):
        if x <= 0:
            return "0"
        exp = int(math.floor(math.log10(x)))
        coef = x / (10 ** exp)
        if abs(coef - round(coef)) < 0.01:
            coef = int(round(coef))
        if exp == 0:
            return f"{coef}"
        elif exp == 1:
            return f"{int(coef * 10)}" if coef != 1 else "10"
        elif exp == 2:
            return f"{int(coef * 100)}" if coef == 1 else f"{coef}×10²"
        else:
            # Use superscript for exponent
            superscripts = "⁰¹²³⁴⁵⁶⁷⁸⁹"
            exp_str = "".join(superscripts[int(d)] for d in str(exp))
            if coef == 1:
                return f"10{exp_str}"
            return f"{coef}×10{exp_str}"
    
    # Set tick locations to actual data points
    if data_xs:
        unique_xs = sorted(set(data_xs))
        ax.xaxis.set_major_locator(FixedLocator(unique_xs))
    ax.xaxis.set_major_formatter(FuncFormatter(sci_formatter))


def main() -> int:
    args = parse_args()
    
    if not args.out_dir:
        # Default to a 'plots' directory in the same location as the summary file
        args.out_dir = os.path.join(os.path.dirname(os.path.abspath(args.summary)), "plots")
        print(f"[plot] No --out-dir provided, using default: {args.out_dir}")

    os.makedirs(args.out_dir, exist_ok=True)

    # Matplotlib availability
    try:
        import matplotlib.pyplot as plt  # type: ignore
    except Exception as e:
        print(f"[plot] matplotlib not available: {e}\nInstall with: pip install matplotlib", file=sys.stderr)
        return 0

    records = load_records(args.summary)
    if not records:
        print("[plot] no records to plot", file=sys.stderr)
        return 0

    payloads = unique_sorted(r["payload"] for r in records)
    transports = unique_sorted(r["transport"] for r in records)

    # Detect latency-only input (no finite sub_tps anywhere)
    latency_only = all(not math.isfinite(rec.get("sub_tps", float("nan"))) for rec in records)

    # For rate-based plots, ignore fanout runs and any rows with non-positive rate or NaN metrics
    if latency_only:
        rate_records = [
            r for r in records
            if not str(r["transport"]).startswith("fanout-") and (r["rate"] or 0) > 0
        ]
    else:
        rate_records = [
            r for r in records
            if not str(r["transport"]).startswith("fanout-")
               and (r["rate"] or 0) > 0
               and math.isfinite(r.get("sub_tps", float("nan")))
        ]
    rates = unique_sorted(r["rate"] for r in rate_records)

    by_pt = defaultdict(list)
    for r in rate_records:
        by_pt[(r["payload"], r["transport"])].append(r)

    # Track images to build a markdown gallery at the end
    throughput_imgs = {}
    p99_imgs = {}
    cpu_imgs = {}
    mem_imgs = {}
    fanout_imgs = {}  # (payload, rate) -> filename
    fanout_cpu_imgs = {}  # (payload, rate) -> filename
    fanout_mem_imgs = {}  # (payload, rate) -> filename
    # New: latency vs payload (for each rate)
    p50_vs_payload_imgs = {}  # rate -> filename
    p95_vs_payload_imgs = {}  # rate -> filename
    p99_vs_payload_imgs = {}  # rate -> filename

    # Throughput vs offered rate (skip if latency-only)
    if not latency_only and not args.only_latency_vs_payload:
        for payload in payloads:
            fig, ax = plt.subplots(figsize=(7, 4))
            for t in transports:
                xs, ys = [], []
                # Preserve input order of rates on X axis
                for rate in rates:
                    vals = [r for r in by_pt[(payload, t)] if r["rate"] == rate]
                    if not vals:
                        continue
                    sub_tps = vals[0]["sub_tps"]
                    if not math.isfinite(sub_tps):
                        continue
                    xs.append(rate)
                    ys.append(sub_tps)
                if xs and ys:
                    m, ls = style_for(t)
                    ax.plot(xs, ys, marker=m, linestyle=ls, label=t)
            ax.set_title(f"Throughput vs Offered Rate (payload={payload}B)")
            ax.set_xlabel("Offered rate (msg/s)")
            ax.set_ylabel("Delivered throughput (msg/s)")
            ax.grid(True, alpha=0.3)
            add_legend_top(ax, fig)
            fn = os.path.join(args.out_dir, f"throughput_vs_rate_payload{payload}.png")
            fig.savefig(fn, dpi=150)
            throughput_imgs[payload] = os.path.basename(fn)
            plt.close(fig)

    # Throughput vs Pairs (when run_id includes n<N>)
    # Only meaningful for non-latency-only inputs
    # Generate both log-scale and linear-scale versions
    if not latency_only and not args.only_latency_vs_payload:
        # Group by payload and transport, aggregate by pairs
        by_pt = defaultdict(list)
        for r in records:
            if not math.isfinite(r.get("sub_tps", float("nan"))):
                continue
            if r.get("pairs") is None:
                continue
            by_pt[(r["payload"], r["transport"])].append(r)
        throughput_pairs_imgs = {}
        throughput_pairs_imgs_linear = {}
        for payload in payloads:
            # Collect data once for both plots
            plot_data = {}  # transport -> (xs, ys)
            all_xs = []
            for t in transports:
                lst = by_pt.get((payload, t), [])
                if not lst:
                    continue
                # Deduplicate by pairs count (keep last entry for each pairs value)
                lst = dedupe_by_pairs(lst)
                lst = sorted(lst, key=lambda x: (x.get("pairs") or 0))
                xs = [x.get("pairs") for x in lst if x.get("pairs") is not None]
                ys = [x.get("sub_tps") for x in lst if x.get("pairs") is not None and math.isfinite(x.get("sub_tps", float("nan")))]
                if xs and ys:
                    plot_data[t] = (xs, ys)
                    all_xs.extend(xs)
            
            if not plot_data:
                continue
            
            # Plot 1: Log scale (existing behavior)
            fig, ax = plt.subplots(figsize=(7, 4))
            for t, (xs, ys) in plot_data.items():
                m, ls = style_for(t)
                ax.plot(xs, ys, marker=m, linestyle=ls, label=t)
            ax.set_title(f"Delivered Throughput vs Pairs (payload={payload}B) [Log Scale]")
            ax.set_xlabel("Pairs (N publishers = N subscribers)")
            ax.set_ylabel("Delivered throughput (msg/s)")
            ax.grid(True, alpha=0.3)
            ax.set_xscale("log")
            format_pairs_axis(ax, all_xs)
            add_legend_top(ax, fig)
            fn = os.path.join(args.out_dir, f"throughput_vs_pairs_payload{payload}_log.png")
            fig.savefig(fn, dpi=150)
            throughput_pairs_imgs[payload] = os.path.basename(fn)
            plt.close(fig)
            
            # Plot 2: Linear scale (new)
            fig, ax = plt.subplots(figsize=(7, 4))
            for t, (xs, ys) in plot_data.items():
                m, ls = style_for(t)
                ax.plot(xs, ys, marker=m, linestyle=ls, label=t)
            ax.set_title(f"Delivered Throughput vs Pairs (payload={payload}B) [Linear Scale]")
            ax.set_xlabel("Pairs (N publishers = N subscribers)")
            ax.set_ylabel("Delivered throughput (msg/s)")
            ax.grid(True, alpha=0.3)
            # Linear scale - use default formatting with thousands separator
            ax.ticklabel_format(style='plain', axis='x')
            try:
                from matplotlib.ticker import FuncFormatter
                ax.xaxis.set_major_formatter(FuncFormatter(lambda x, p: format(int(x), ',')))
            except Exception:
                pass
            add_legend_top(ax, fig)
            fn = os.path.join(args.out_dir, f"throughput_vs_pairs_payload{payload}_linear.png")
            fig.savefig(fn, dpi=150)
            throughput_pairs_imgs_linear[payload] = os.path.basename(fn)
            plt.close(fig)

    # Latency vs Pairs (when run_id includes n<N>)
    # Generate for any dataset type (latency-only or full), using p50/p95/p99
    # Group by payload and transport, aggregate by pairs
    if not args.only_latency_vs_payload:
        by_pt_lat_pairs = defaultdict(list)
        for r in records:
            if r.get("pairs") is None:
                continue
            by_pt_lat_pairs[(r["payload"], r["transport"])].append(r)

        latency_pairs_imgs_p50 = {}
        latency_pairs_imgs_p95 = {}
        latency_pairs_imgs_p99 = {}
    else:
        by_pt_lat_pairs = {}
        latency_pairs_imgs_p50 = {}
        latency_pairs_imgs_p95 = {}
        latency_pairs_imgs_p99 = {}

    def plot_latency_pairs(metric_key: str, title_prefix: str) -> dict:
        out = {}
        for payload in payloads:
            fig, ax = plt.subplots(figsize=(7, 4))
            all_xs = []  # Collect all x values for axis formatting
            for t in transports:
                lst = by_pt_lat_pairs.get((payload, t), [])
                if not lst:
                    continue
                # Deduplicate by pairs count (keep last entry for each pairs value)
                lst = dedupe_by_pairs(lst)
                lst = sorted(lst, key=lambda x: (x.get("pairs") or 0))
                xs, ys = [], []
                for x in lst:
                    pairs = x.get("pairs")
                    val = x.get(metric_key)
                    if pairs is None or val is None or (not math.isfinite(val)) or (val <= 0):
                        continue
                    xs.append(pairs)
                    ys.append(val)
                if xs and ys:
                    m, ls = style_for(t)
                    ax.plot(xs, ys, marker=m, linestyle=ls, label=t)
                    all_xs.extend(xs)
            if not ax.has_data():
                plt.close(fig)
                continue
            ax.set_title(f"{title_prefix} vs Pairs (payload={payload}B)")
            ax.set_xlabel("Pairs (N publishers = N subscribers)")
            ax.set_ylabel(f"{title_prefix} (ms)")
            ax.grid(True, alpha=0.3)
            # Use log scales for readability and latency convention
            try:
                ax.set_xscale("log")
            except Exception:
                pass
            try:
                ax.set_yscale("log")
            except Exception:
                pass
            format_pairs_axis(ax, all_xs)
            add_legend_top(ax, fig)
            fn = os.path.join(args.out_dir, f"{metric_key}_vs_pairs_payload{payload}.png")
            fig.savefig(fn, dpi=150)
            out[payload] = os.path.basename(fn)
            plt.close(fig)
        return out

    if by_pt_lat_pairs:
        latency_pairs_imgs_p50 = plot_latency_pairs("p50_ms", "P50 latency")
        latency_pairs_imgs_p95 = plot_latency_pairs("p95_ms", "P95 latency")
        latency_pairs_imgs_p99 = plot_latency_pairs("p99_ms", "P99 latency")

    # CPU/Memory vs Pairs (when run_id includes n<N>)
    cpu_pairs_imgs = {}
    mem_pairs_imgs = {}
    avg_cpu_pairs_imgs = {}
    avg_mem_pairs_imgs = {}

    def plot_metric_vs_pairs(metric_key: str, title_prefix: str, y_label: str) -> dict:
        out = {}
        if args.only_latency_vs_payload:
            return out
        for payload in payloads:
            fig, ax = plt.subplots(figsize=(7, 4))
            all_xs = []  # Collect all x values for axis formatting
            for t in transports:
                lst = by_pt_lat_pairs.get((payload, t), [])
                if not lst:
                    continue
                # Deduplicate by pairs count (keep last entry for each pairs value)
                lst = dedupe_by_pairs(lst)
                lst = sorted(lst, key=lambda x: (x.get("pairs") or 0))
                xs, ys = [], []
                for x in lst:
                    pairs = x.get("pairs")
                    val = x.get(metric_key)
                    if pairs is None or val is None or (not math.isfinite(val)):
                        continue
                    xs.append(pairs)
                    ys.append(val)
                if xs and ys:
                    m, ls = style_for(t)
                    ax.plot(xs, ys, marker=m, linestyle=ls, label=t)
                    all_xs.extend(xs)
            if not ax.has_data():
                plt.close(fig)
                continue
            ax.set_title(f"{title_prefix} vs Pairs (payload={payload}B)")
            ax.set_xlabel("Pairs (N publishers = N subscribers)")
            ax.set_ylabel(y_label)
            ax.grid(True, alpha=0.3)
            try:
                ax.set_xscale("log")
            except Exception:
                pass
            format_pairs_axis(ax, all_xs)
            add_legend_top(ax, fig)
            fn = os.path.join(args.out_dir, f"{metric_key}_vs_pairs_payload{payload}.png")
            fig.savefig(fn, dpi=150)
            out[payload] = os.path.basename(fn)
            plt.close(fig)
        return out

    if by_pt_lat_pairs:
        cpu_pairs_imgs = plot_metric_vs_pairs("max_cpu", "Max CPU%", "Max CPU (%)")
        mem_pairs_imgs = plot_metric_vs_pairs("max_mem_perc", "Max Memory%", "Max Memory (%)")
        avg_cpu_pairs_imgs = plot_metric_vs_pairs("avg_cpu", "Avg CPU%", "Avg CPU (%)")
        avg_mem_pairs_imgs = plot_metric_vs_pairs("avg_mem_perc", "Avg Memory%", "Avg Memory (%)")

    # P99 vs offered rate (skip if latency-only; it's rate-based summary)
    if not latency_only and not args.only_latency_vs_payload:
        for payload in payloads:
            fig, ax = plt.subplots(figsize=(7, 4))
            for t in transports:
                xs, ys = [], []
                for rate in rates:
                    vals = [r for r in by_pt[(payload, t)] if r["rate"] == rate]
                    if not vals:
                        continue
                    p99 = vals[0]["p99_ms"]
                    # Require finite and strictly positive for log-scale
                    if (not math.isfinite(p99)) or (p99 <= 0):
                        continue
                    xs.append(rate)
                    ys.append(p99)
                if xs and ys:
                    m, ls = style_for(t)
                    ax.plot(xs, ys, marker=m, linestyle=ls, label=t)
            ax.set_title(f"P99 latency vs Offered Rate (payload={payload}B)")
            ax.set_xlabel("Offered rate (msg/s)")
            ax.set_ylabel("P99 latency (ms)")
            # Use logarithmic Y-axis for latency
            try:
                ax.set_yscale("log")
            except Exception:
                pass
            ax.grid(True, alpha=0.3)
            add_legend_top(ax, fig)
            fn = os.path.join(args.out_dir, f"p99_vs_rate_payload{payload}.png")
            fig.savefig(fn, dpi=150)
            p99_imgs[payload] = os.path.basename(fn)
            plt.close(fig)

    # Max CPU% vs offered rate (skip if latency-only)
    if not latency_only and not args.only_latency_vs_payload:
        for payload in payloads:
            fig, ax = plt.subplots(figsize=(7, 4))
            for t in transports:
                xs, ys = [], []
                for rate in rates:
                    vals = [r for r in by_pt[(payload, t)] if r["rate"] == rate]
                    if not vals:
                        continue
                    mc = vals[0].get("max_cpu")
                    if mc is None or not math.isfinite(mc):
                        continue
                    xs.append(rate)
                    ys.append(mc)
                if xs and ys:
                    m, ls = style_for(t)
                    ax.plot(xs, ys, marker=m, linestyle=ls, label=t)
            ax.set_title(f"Max CPU% vs Offered Rate (payload={payload}B)")
            ax.set_xlabel("Offered rate (msg/s)")
            ax.set_ylabel("Max CPU (%)")
            ax.grid(True, alpha=0.3)
            add_legend_top(ax, fig)
            fn = os.path.join(args.out_dir, f"max_cpu_vs_rate_payload{payload}.png")
            fig.savefig(fn, dpi=150)
            cpu_imgs[payload] = os.path.basename(fn)
            plt.close(fig)

    # Max Memory% vs offered rate (skip if latency-only)
    if not latency_only and not args.only_latency_vs_payload:
        for payload in payloads:
            fig, ax = plt.subplots(figsize=(7, 4))
            for t in transports:
                xs, ys = [], []
                for rate in rates:
                    vals = [r for r in by_pt[(payload, t)] if r["rate"] == rate]
                    if not vals:
                        continue
                    mm = vals[0].get("max_mem_perc")
                    if mm is None or not math.isfinite(mm):
                        continue
                    xs.append(rate)
                    ys.append(mm)
                if xs and ys:
                    m, ls = style_for(t)
                    ax.plot(xs, ys, marker=m, linestyle=ls, label=t)
            ax.set_title(f"Max Memory% vs Offered Rate (payload={payload}B)")
            ax.set_xlabel("Offered rate (msg/s)")
            ax.set_ylabel("Max Memory (%)")
            ax.grid(True, alpha=0.3)
            add_legend_top(ax, fig)
            fn = os.path.join(args.out_dir, f"max_mem_vs_rate_payload{payload}.png")
            fig.savefig(fn, dpi=150)
            mem_imgs[payload] = os.path.basename(fn)
            plt.close(fig)

    # Latency vs Payload (for each offered rate)
    # One figure per rate; X = payload (bytes), Y = latency (ms); lines per transport
    from matplotlib.ticker import FuncFormatter, MaxNLocator

    def plot_metric_vs_payload(metric_key: str, title_prefix: str, y_label: str, dataset, log_y: bool = True) -> dict:
        out = {}
        for rate in rates:
            fig, ax = plt.subplots(figsize=(7, 4))
            log_kb_set = set()
            for t in transports:
                # gather all records for this (rate, transport) across payloads
                lst = [r for r in dataset if r["rate"] == rate and r["transport"] == t]
                if not lst:
                    continue
                # sort by payload
                lst = sorted(lst, key=lambda x: x["payload"])
                xs, ys = [], []
                for r in lst:
                    val = r.get(metric_key)
                    # Require finite
                    if val is None or (not math.isfinite(val)):
                        continue
                    # For log scale, require strictly positive
                    if log_y and val <= 0:
                        continue

                    # Convert bytes to KB, then take log2
                    # payload is in bytes. 1KB = 1024 bytes.
                    # log2(payload / 1024)
                    try:
                        x_log = math.log2(r["payload"] / 1024.0)
                    except ValueError:
                        continue
                    
                    xs.append(x_log)
                    log_kb_set.add(x_log)
                    ys.append(val)
                if xs and ys:
                    m, ls = style_for(t)
                    ax.plot(xs, ys, marker=m, linestyle=ls, label=t)
            
            if not ax.has_data():
                plt.close(fig)
                continue

            ax.set_title(f"{title_prefix} vs Payload (rate={rate}/s)")
            ax.set_xlabel("Payload size (log2 KB)")
            ax.set_ylabel(y_label)
            
            if log_y:
                try:
                    ax.set_yscale("log")
                except Exception:
                    pass
            else:
                ax.set_ylim(bottom=0)

            ax.grid(True, alpha=0.3)
            
            if log_kb_set:
                xs_sorted = sorted(log_kb_set)
                # Add a small margin to x-axis so markers aren't cut off
                margin = 0.5 if len(xs_sorted) > 1 else 0.1
                try:
                    ax.set_xlim(left=min(xs_sorted) - margin, right=max(xs_sorted) + margin)
                except Exception:
                    pass
                ax.set_xticks(xs_sorted)
            
            # Format ticks as integer if they are close to integer
            def log_formatter(v, pos):
                if abs(v - round(v)) < 0.001:
                    return f"{int(round(v))}"
                return f"{v:.1f}"

            ax.xaxis.set_major_formatter(FuncFormatter(log_formatter))
            
            add_legend_top(ax, fig)
            fn = os.path.join(args.out_dir, f"{metric_key}_vs_payload_rate{rate}.png")
            fig.savefig(fn, dpi=150)
            out[rate] = os.path.basename(fn)
            plt.close(fig)
        return out

    # Use the appropriate dataset for latency vs payload
    latency_dataset = rate_records
    # Generate p50/p95/p99 vs payload (per rate)
    p50_vs_payload_imgs = plot_metric_vs_payload("p50_ms", "P50 latency", "P50 latency (ms)", latency_dataset, log_y=True)
    p95_vs_payload_imgs = plot_metric_vs_payload("p95_ms", "P95 latency", "P95 latency (ms)", latency_dataset, log_y=True)
    p99_vs_payload_imgs = plot_metric_vs_payload("p99_ms", "P99 latency", "P99 latency (ms)", latency_dataset, log_y=True)
    
    # Generate CPU/Memory vs payload (per rate)
    cpu_vs_payload_imgs = plot_metric_vs_payload("max_cpu", "Max CPU%", "Max CPU (%)", latency_dataset, log_y=False)
    mem_vs_payload_imgs = plot_metric_vs_payload("max_mem_perc", "Max Memory%", "Max Memory (%)", latency_dataset, log_y=False)


    # Fanout plots: x = subscriber count, y = delivered throughput, per (payload, rate)
    fanout_rows = []
    if not args.only_latency_vs_payload:
        subs_pat = re.compile(r"-s(\d+)$")
        for r in records:
            t = r["transport"]
            if t.startswith("fanout-"):
                m = subs_pat.search(t)
                if not m:
                    continue
                try:
                    subs = int(m.group(1))
                except Exception:
                    continue
                # Normalize label e.g. fanout-mqtt-hivemq-s8 -> mqtt-hivemq
                base_label = t[: t.rfind("-s")]
                if base_label.startswith("fanout-"):
                    base_label = base_label[len("fanout-"):]
                fanout_rows.append({
                    "payload": r["payload"],
                    "rate": r["rate"],
                    "subs": subs,
                    "sub_tps": r["sub_tps"],
                    "max_cpu": r.get("max_cpu"),
                    "max_mem_perc": r.get("max_mem_perc"),
                    "label": base_label,
                })

    if fanout_rows:
        by_pr = defaultdict(list)  # (payload, rate) -> rows
        for r in fanout_rows:
            by_pr[(r["payload"], r["rate"])].append(r)
        for (payload, rate), rows in by_pr.items():
            # Group by label in case multiple fanout transport flavors exist
            by_label = defaultdict(list)
            for rr in rows:
                by_label[rr["label"]].append(rr)

            fig, ax = plt.subplots(figsize=(7, 4))
            for label, lst in by_label.items():
                lst = sorted(lst, key=lambda x: x["subs"])
                xs = [x["subs"] for x in lst if math.isfinite(x.get("sub_tps", float("nan")))]
                ys = [x["sub_tps"] for x in lst if math.isfinite(x.get("sub_tps", float("nan")))]
                m, ls = style_for(label)
                ax.plot(xs, ys, marker=m, linestyle=ls, label=label)
            ax.set_title(f"Delivered throughput vs Fanout (payload={payload}B, rate={rate}/s)")
            ax.set_xlabel("Fanout (subscribers)")
            ax.set_ylabel("Delivered throughput (msg/s)")
            ax.grid(True, alpha=0.3)
            add_legend_top(ax, fig)
            fn = os.path.join(args.out_dir, f"throughput-vs-fanout_payload{payload}_rate{rate}.png")
            fig.savefig(fn, dpi=150)
            fanout_imgs[(payload, rate)] = os.path.basename(fn)
            plt.close(fig)

            # CPU vs fanout
            fig, ax = plt.subplots(figsize=(7, 4))
            for label, lst in by_label.items():
                lst = sorted(lst, key=lambda x: x["subs"])
                xs, ys = [], []
                for x in lst:
                    v = x.get("max_cpu")
                    if v is None or not math.isfinite(v):
                        continue
                    xs.append(x["subs"]) 
                    ys.append(v)
                if xs and ys:
                    m, ls = style_for(label)
                    ax.plot(xs, ys, marker=m, linestyle=ls, label=label)
            ax.set_title(f"Max CPU% vs Fanout (payload={payload}B, rate={rate}/s)")
            ax.set_xlabel("Fanout (subscribers)")
            ax.set_ylabel("Max CPU (%)")
            ax.grid(True, alpha=0.3)
            add_legend_top(ax, fig)
            fn_cpu = os.path.join(args.out_dir, f"max-cpu-vs-fanout_payload{payload}_rate{rate}.png")
            fig.savefig(fn_cpu, dpi=150)
            fanout_cpu_imgs[(payload, rate)] = os.path.basename(fn_cpu)
            plt.close(fig)

            # Memory% vs fanout
            fig, ax = plt.subplots(figsize=(7, 4))
            for label, lst in by_label.items():
                lst = sorted(lst, key=lambda x: x["subs"])
                xs, ys = [], []
                for x in lst:
                    v = x.get("max_mem_perc")
                    if v is None or not math.isfinite(v):
                        continue
                    xs.append(x["subs"]) 
                    ys.append(v)
                if xs and ys:
                    m, ls = style_for(label)
                    ax.plot(xs, ys, marker=m, linestyle=ls, label=label)
            ax.set_title(f"Max Memory% vs Fanout (payload={payload}B, rate={rate}/s)")
            ax.set_xlabel("Fanout (subscribers)")
            ax.set_ylabel("Max Memory (%)")
            ax.grid(True, alpha=0.3)
            add_legend_top(ax, fig)
            fn_mem = os.path.join(args.out_dir, f"max-memory-vs-fanout_payload{payload}_rate{rate}.png")
            fig.savefig(fn_mem, dpi=150)
            fanout_mem_imgs[(payload, rate)] = os.path.basename(fn_mem)
            plt.close(fig)

    # Build a simple markdown gallery
    try:
        md_path = os.path.join(args.out_dir, "README.md")
        with open(md_path, "w", encoding="utf-8") as f:
            f.write("# Benchmark plots\n\n")
            f.write(f"- Summary: `{os.path.abspath(args.summary)}`\n\n")

            # Table of contents
            f.write("## Table of contents\n\n")
            if throughput_imgs:
                f.write("- [Throughput vs Offered Rate](#throughput-vs-offered-rate)\n")
            if p99_imgs:
                f.write("- [P99 latency vs Offered Rate](#p99-latency-vs-offered-rate)\n")
            if cpu_imgs:
                f.write("- [Max CPU% vs Offered Rate](#max-cpu-vs-offered-rate)\n")
            if mem_imgs:
                f.write("- [Max Memory% vs Offered Rate](#max-memory-vs-offered-rate)\n")
            if fanout_imgs:
                f.write("- [Fanout: Delivered throughput](#fanout-delivered-throughput)\n")
            if fanout_cpu_imgs:
                f.write("- [Fanout: Max CPU%](#fanout-max-cpu)\n")
            if fanout_mem_imgs:
                f.write("- [Fanout: Max Memory%](#fanout-max-memory)\n")
            # TOC entries for pairs plots
            try:
                if 'throughput_pairs_imgs' in locals() and throughput_pairs_imgs:
                    f.write("- [Throughput vs Pairs](#throughput-vs-pairs)\n")
            except Exception:
                pass
            try:
                if ('latency_pairs_imgs_p50' in locals() and latency_pairs_imgs_p50) or \
                   ('latency_pairs_imgs_p95' in locals() and latency_pairs_imgs_p95) or \
                   ('latency_pairs_imgs_p99' in locals() and latency_pairs_imgs_p99):
                    f.write("- [Latency vs Pairs](#latency-vs-pairs)\n")
            except Exception:
                pass
            try:
                if 'cpu_pairs_imgs' in locals() and cpu_pairs_imgs:
                    f.write("- [Max CPU% vs Pairs](#max-cpu-vs-pairs)\n")
            except Exception:
                pass
            try:
                if 'mem_pairs_imgs' in locals() and mem_pairs_imgs:
                    f.write("- [Max Memory% vs Pairs](#max-memory-vs-pairs)\n")
            except Exception:
                pass
            try:
                if 'avg_cpu_pairs_imgs' in locals() and avg_cpu_pairs_imgs:
                    f.write("- [Avg CPU% vs Pairs](#avg-cpu-vs-pairs)\n")
            except Exception:
                pass
            try:
                if 'avg_mem_pairs_imgs' in locals() and avg_mem_pairs_imgs:
                    f.write("- [Avg Memory% vs Pairs](#avg-memory-vs-pairs)\n")
            except Exception:
                pass

            if p50_vs_payload_imgs or p95_vs_payload_imgs or p99_vs_payload_imgs:
                f.write("- [Latency vs Payload](#latency-vs-payload)\n")
            if cpu_vs_payload_imgs or mem_vs_payload_imgs:
                f.write("- [Resource Usage vs Payload](#resource-usage-vs-payload)\n")

            f.write("\n")

            if throughput_imgs:
                f.write("## Throughput vs Offered Rate\n\n")
                for payload in payloads:
                    img = throughput_imgs.get(payload)
                    if not img:
                        continue
                    f.write(f"### payload={payload}B\n\n")
                    f.write(f"![throughput payload {payload}]({img})\n\n")

            # Insert Throughput vs Pairs section if generated
            try:
                if 'throughput_pairs_imgs' in locals() and throughput_pairs_imgs:
                    f.write("## Throughput vs Pairs\n\n")
                    for payload in payloads:
                        img_log = throughput_pairs_imgs.get(payload)
                        img_linear = throughput_pairs_imgs_linear.get(payload) if 'throughput_pairs_imgs_linear' in locals() else None
                        if not img_log and not img_linear:
                            continue
                        f.write(f"### payload={payload}B\n\n")
                        if img_log:
                            f.write(f"**Log Scale:**\n\n")
                            f.write(f"![throughput vs pairs payload {payload} log]({img_log})\n\n")
                        if img_linear:
                            f.write(f"**Linear Scale:**\n\n")
                            f.write(f"![throughput vs pairs payload {payload} linear]({img_linear})\n\n")
            except Exception:
                pass

            # Insert Latency vs Pairs section if generated
            try:
                have_lat_pairs = (
                    ('latency_pairs_imgs_p50' in locals() and latency_pairs_imgs_p50) or
                    ('latency_pairs_imgs_p95' in locals() and latency_pairs_imgs_p95) or
                    ('latency_pairs_imgs_p99' in locals() and latency_pairs_imgs_p99)
                )
                if have_lat_pairs:
                    f.write("## Latency vs Pairs\n\n")
                    if 'latency_pairs_imgs_p50' in locals() and latency_pairs_imgs_p50:
                        f.write("### P50 latency\n\n")
                        for payload in payloads:
                            img = latency_pairs_imgs_p50.get(payload)
                            if not img:
                                continue
                            f.write(f"#### payload={payload}B\n\n")
                            f.write(f"![p50 vs pairs payload {payload}]({img})\n\n")
                    if 'latency_pairs_imgs_p95' in locals() and latency_pairs_imgs_p95:
                        f.write("### P95 latency\n\n")
                        for payload in payloads:
                            img = latency_pairs_imgs_p95.get(payload)
                            if not img:
                                continue
                            f.write(f"#### payload={payload}B\n\n")
                            f.write(f"![p95 vs pairs payload {payload}]({img})\n\n")
                    if 'latency_pairs_imgs_p99' in locals() and latency_pairs_imgs_p99:
                        f.write("### P99 latency\n\n")
                        for payload in payloads:
                            img = latency_pairs_imgs_p99.get(payload)
                            if not img:
                                continue
                            f.write(f"#### payload={payload}B\n\n")
                            f.write(f"![p99 vs pairs payload {payload}]({img})\n\n")
            except Exception:
                pass

            # Insert CPU/Memory vs Pairs section if generated
            try:
                if 'cpu_pairs_imgs' in locals() and cpu_pairs_imgs:
                    f.write("## Max CPU% vs Pairs\n\n")
                    for payload in payloads:
                        img = cpu_pairs_imgs.get(payload)
                        if not img:
                            continue
                        f.write(f"### payload={payload}B\n\n")
                        f.write(f"![cpu vs pairs payload {payload}]({img})\n\n")
            except Exception:
                pass

            try:
                if 'mem_pairs_imgs' in locals() and mem_pairs_imgs:
                    f.write("## Max Memory% vs Pairs\n\n")
                    for payload in payloads:
                        img = mem_pairs_imgs.get(payload)
                        if not img:
                            continue
                        f.write(f"### payload={payload}B\n\n")
                        f.write(f"![mem vs pairs payload {payload}]({img})\n\n")
            except Exception:
                pass

            # Insert Avg CPU/Memory vs Pairs section if generated
            try:
                if 'avg_cpu_pairs_imgs' in locals() and avg_cpu_pairs_imgs:
                    f.write("## Avg CPU% vs Pairs\n\n")
                    for payload in payloads:
                        img = avg_cpu_pairs_imgs.get(payload)
                        if not img:
                            continue
                        f.write(f"### payload={payload}B\n\n")
                        f.write(f"![avg cpu vs pairs payload {payload}]({img})\n\n")
            except Exception:
                pass

            try:
                if 'avg_mem_pairs_imgs' in locals() and avg_mem_pairs_imgs:
                    f.write("## Avg Memory% vs Pairs\n\n")
                    for payload in payloads:
                        img = avg_mem_pairs_imgs.get(payload)
                        if not img:
                            continue
                        f.write(f"### payload={payload}B\n\n")
                        f.write(f"![avg mem vs pairs payload {payload}]({img})\n\n")
            except Exception:
                pass

            if p99_imgs:
                f.write("## P99 latency vs Offered Rate\n\n")
                for payload in payloads:
                    img = p99_imgs.get(payload)
                    if not img:
                        continue
                    f.write(f"### payload={payload}B\n\n")
                    f.write(f"![p99 payload {payload}]({img})\n\n")

            if cpu_imgs:
                f.write("## Max CPU% vs Offered Rate\n\n")
                for payload in payloads:
                    img = cpu_imgs.get(payload)
                    if not img:
                        continue
                    f.write(f"### payload={payload}B\n\n")
                    f.write(f"![cpu payload {payload}]({img})\n\n")

            if mem_imgs:
                f.write("## Max Memory% vs Offered Rate\n\n")
                for payload in payloads:
                    img = mem_imgs.get(payload)
                    if not img:
                        continue
                    f.write(f"### payload={payload}B\n\n")
                    f.write(f"![mem payload {payload}]({img})\n\n")

            # Latency vs Payload (per rate)
            if p50_vs_payload_imgs or p95_vs_payload_imgs or p99_vs_payload_imgs:
                f.write("## Latency vs Payload\n\n")
                if p50_vs_payload_imgs:
                    f.write("### P50 latency\n\n")
                    for rate in sorted(p50_vs_payload_imgs.keys()):
                        img = p50_vs_payload_imgs[rate]
                        f.write(f"#### rate={rate}/s\n\n")
                        f.write(f"![p50 vs payload r{rate}]({img})\n\n")
                if p95_vs_payload_imgs:
                    f.write("### P95 latency\n\n")
                    for rate in sorted(p95_vs_payload_imgs.keys()):
                        img = p95_vs_payload_imgs[rate]
                        f.write(f"#### rate={rate}/s\n\n")
                        f.write(f"![p95 vs payload r{rate}]({img})\n\n")
                if p99_vs_payload_imgs:
                    f.write("### P99 latency\n\n")
                    for rate in sorted(p99_vs_payload_imgs.keys()):
                        img = p99_vs_payload_imgs[rate]
                        f.write(f"#### rate={rate}/s\n\n")
                        f.write(f"![p99 vs payload r{rate}]({img})\n\n")

            # Resource Usage vs Payload (per rate)
            if cpu_vs_payload_imgs or mem_vs_payload_imgs:
                f.write("## Resource Usage vs Payload\n\n")
                if cpu_vs_payload_imgs:
                    f.write("### Max CPU%\n\n")
                    for rate in sorted(cpu_vs_payload_imgs.keys()):
                        img = cpu_vs_payload_imgs[rate]
                        f.write(f"#### rate={rate}/s\n\n")
                        f.write(f"![cpu vs payload r{rate}]({img})\n\n")
                if mem_vs_payload_imgs:
                    f.write("### Max Memory%\n\n")
                    for rate in sorted(mem_vs_payload_imgs.keys()):
                        img = mem_vs_payload_imgs[rate]
                        f.write(f"#### rate={rate}/s\n\n")
                        f.write(f"![mem vs payload r{rate}]({img})\n\n")

            if fanout_imgs:
                f.write("## Fanout: Delivered throughput\n\n")
                # Group by payload, then rate for consistent order
                pr_keys = sorted(fanout_imgs.keys())
                by_p = defaultdict(list)
                for (p, r) in pr_keys:
                    by_p[p].append(r)
                for p in sorted(by_p.keys()):
                    f.write(f"### payload={p}B\n\n")
                    for r in sorted(set(by_p[p])):
                        img = fanout_imgs.get((p, r))
                        if not img:
                            continue
                        f.write(f"#### rate={r}/s\n\n")
                        f.write(f"![fanout p{p} r{r}]({img})\n\n")

            if fanout_cpu_imgs:
                f.write("## Fanout: Max CPU%\n\n")
                pr_keys = sorted(fanout_cpu_imgs.keys())
                by_p = defaultdict(list)
                for (p, r) in pr_keys:
                    by_p[p].append(r)
                for p in sorted(by_p.keys()):
                    f.write(f"### payload={p}B\n\n")
                    for r in sorted(set(by_p[p])):
                        img = fanout_cpu_imgs.get((p, r))
                        if not img:
                            continue
                        f.write(f"#### rate={r}/s\n\n")
                        f.write(f"![fanout cpu p{p} r{r}]({img})\n\n")

            if fanout_mem_imgs:
                f.write("## Fanout: Max Memory%\n\n")
                pr_keys = sorted(fanout_mem_imgs.keys())
                by_p = defaultdict(list)
                for (p, r) in pr_keys:
                    by_p[p].append(r)
                for p in sorted(by_p.keys()):
                    f.write(f"### payload={p}B\n\n")
                    for r in sorted(set(by_p[p])):
                        img = fanout_mem_imgs.get((p, r))
                        if not img:
                            continue
                        f.write(f"#### rate={r}/s\n\n")
                        f.write(f"![fanout mem p{p} r{r}]({img})\n\n")

        print("[plot] Wrote plots to", args.out_dir)
        print("[plot] Wrote gallery:", md_path)
    except Exception as e:
        print(f"[plot] failed to write README.md: {e}", file=sys.stderr)
        print("[plot] Wrote plots to", args.out_dir)
    return 0


if __name__ == "__main__":
    raise SystemExit(main())
